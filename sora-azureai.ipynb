{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f292f216-448c-4304-8224-0cbf9a2022c9",
   "metadata": {},
   "source": [
    "# Sora with Azure AI Foundry\n",
    "\n",
    "Sora is an AI model from OpenAI that can create realistic and imaginative video scenes from text instructions. The model is capable of generating a wide range of video content, including realistic scenes, animations, and special effects. Several video resolutions and durations are supported.\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/video-generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6091b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python_dotenv\n",
    "%pip install requests\n",
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efafceee-6fbf-401d-bae8-824767771471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import datetime\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Video, FileLink\n",
    "from moviepy import *\n",
    "from openai import OpenAI\n",
    "from openai.types.video_seconds import VideoSeconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029dd448-1591-4548-9e75-281d717a3062",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd844f89-064a-4146-97b0-8bff137f02f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Today is {datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c533a5-8e6e-426d-8010-684fc17b380b",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560fe98b-dcdc-40d7-a449-152e77ff6359",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_DIR = \"videos\"\n",
    "\n",
    "if os.path.exists(VIDEO_DIR) and os.path.isdir(VIDEO_DIR):\n",
    "    shutil.rmtree(VIDEO_DIR)\n",
    "\n",
    "os.makedirs(VIDEO_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5143ddfb-603d-4cef-ad78-fefa7ed70c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "endpoint = requests.get('https://func-sora-lab-hca7gbc4c2euhpe5.spaincentral-01.azurewebsites.net/api/p36sx7slxn').content.decode('utf-8').strip()\n",
    "api_key = requests.get('https://func-sora-lab-hca7gbc4c2euhpe5.spaincentral-01.azurewebsites.net/api/s78nm270dh').content.decode('utf-8').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651cad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=f\"{endpoint}/openai/v1/\",\n",
    "    api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20797e2-8ca9-4f63-954f-2bfa1723b3be",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9688580-4ed4-4e58-b162-ca62613b5e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_video_sora2(prompt: str, size: str = \"1280x720\", seconds: str = \"8\") -> str:\n",
    "    \"\"\"\n",
    "    Generate a video using the SORA-2 model deployed in Azure AI Foundry.\n",
    "\n",
    "    This function sends a video generation request to the Azure AI Foundry client,\n",
    "    polls for the job status until completion (or failure), and downloads the\n",
    "    resulting video file locally.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): A detailed text description of the video scene to generate.\n",
    "                      Example: \"A professional two-person interview about Microsoft Azure...\"\n",
    "        size (str, optional): The resolution of the output video. Defaults to \"1280x720\".\n",
    "                              Supported values: \"1280x720\" (landscape) or \"720x1280\" (portrait).\n",
    "        seconds (str, optional): Duration of the generated video in seconds.\n",
    "                                 Supported values: \"4\", \"8\", or \"12\". Defaults to \"8\".\n",
    "\n",
    "    Returns:\n",
    "        str: The local file path of the downloaded video if generation succeeds.\n",
    "        bool: False if the generation fails or is cancelled.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    # Create video with custom parameters\n",
    "    print(f\"===== üé® Creating SORA-2 video using Azure AI Foundry =====\\n\")\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "\n",
    "    try:\n",
    "        video = client.videos.create(\n",
    "            model=\"sora-2\",  # The name of your sora2 deployed model in Azure AI Foundry\n",
    "            prompt=prompt,  # text prompt\n",
    "            size=size,  # 1280x720 or 720x1280\n",
    "            seconds=seconds  # \"4\", \"8\", or \"12\" seconds\n",
    "        )\n",
    "\n",
    "        print(f\"üìπ Video ID: {video.id}\")\n",
    "        print(f\"‚è≥ Initial Status: {video.status}\\n\")\n",
    "\n",
    "        # Poll for completion\n",
    "        while video.status not in [\"completed\", \"failed\", \"cancelled\"]:\n",
    "            now = datetime.datetime.now().strftime('%d-%b-%Y %H:%M:%S')\n",
    "            print(f\"[{now}] ‚è±Ô∏è Status: {video.status}\")\n",
    "            time.sleep(10)  # Pause\n",
    "            video = client.videos.retrieve(video.id)\n",
    "\n",
    "        # Handle final status\n",
    "        if video.status == \"completed\":\n",
    "            print(\"\\n‚ú® Video generation completed!\")\n",
    "            print(\"üì• Downloading video\")\n",
    "            content = client.videos.download_content(video.id, variant=\"video\")\n",
    "            sora2_videofile = os.path.join(\n",
    "                VIDEO_DIR,\n",
    "                f\"sora2_video_{datetime.datetime.now().strftime('%d%b%Y_%H%M%S')}.mp4\"\n",
    "            )\n",
    "            content.write_to_file(sora2_videofile)\n",
    "            minutes, seconds = divmod((time.time() - start), 60)\n",
    "            print(f\"‚è±Ô∏è Done in {minutes:.0f} minutes and {seconds:.0f} seconds\")\n",
    "            print(f\"\\n‚úÖ Video saved to: {sora2_videofile}\")\n",
    "            return sora2_videofile\n",
    "\n",
    "        elif video.status == \"failed\":\n",
    "            print(\"\\n‚ùå Video generation failed!\")\n",
    "            return False\n",
    "\n",
    "        elif video.status == \"cancelled\":\n",
    "            print(\"\\n‚ö†Ô∏è Video generation was cancelled\")\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nüö® Error occurred: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b865643f-526e-409c-8ba8-9d8ee7a8ea46",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc275668",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Funny video of a snail jumping from an airplane flying over mountains.\n",
    "\"\"\"\n",
    "\n",
    "sora2_videofile = text_to_video_sora2(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2d758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(sora2_videofile, width=1024, embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950e76ca-3c62-45cb-bfbe-de46f8acf1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Advertising luxury perfume with a blond female model holding the perfume with Paris sunset behind her.\n",
    "The perfume name is 'Velour Eclipse'.\n",
    "She is saying 'Velour Eclipse perfume from Paris: Wear the eclipse, Own the night.'.\n",
    "Print 'Velour Eclipse' at the end of the video.\n",
    "\"\"\"\n",
    "\n",
    "sora2_videofile = text_to_video_sora2(prompt, size=\"1280x720\", seconds=\"8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd7d05f-5314-4bee-aab2-209d60adab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(sora2_videofile, width=1024, embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ea0c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "1. Style: 1970s romantic drama, shot on 35 mm film with natural flares, soft focus, and warm halation.\n",
    "Slight gate weave and handheld micro-shake evoke vintage intimacy.\n",
    "Warm Kodak-inspired grade; light halation on bulbs; film grain and soft vignette for period authenticity.\n",
    "At golden hour, a brick tenement rooftop transforms into a small stage.\n",
    "Laundry lines strung with white sheets sway in the wind, catching the last rays of sunlight.\n",
    "Strings of mismatched fairy bulbs hum faintly overhead. A young woman in a flowing red silk dress dances barefoot, curls glowing in the fading light.\n",
    "Her partner ‚Äî sleeves rolled, suspenders loose ‚Äî claps along, his smile wide and unguarded.\n",
    "Below, the city hums with car horns, subway tremors, and distant laughter.\n",
    "\n",
    "2. Cinematography:\n",
    "Camera: medium-wide shot, slow dolly-in from eye level.\n",
    "Lens: 40 mm spherical; shallow focus to isolate the couple from skyline.\n",
    "Lighting: golden natural key with tungsten bounce; edge from fairy bulbs.\n",
    "Mood: nostalgic, tender, cinematic.\n",
    "\n",
    "3. Actions:\n",
    "- She spins; her dress flares, catching sunlight.\n",
    "- Woman (laughing): 'See? Even the city dances with us tonight.'\n",
    "- He steps in, catches her hand, and dips her into shadow.\n",
    "- Man (smiling): 'Only because you lead!'\n",
    "- Sheets drift across frame, briefly veiling the skyline before parting again.\n",
    "\n",
    "4. Background Sound:\n",
    "Natural ambience only: faint wind, fabric flutter, street noise, typical '70s music.\n",
    "\"\"\"\n",
    "\n",
    "sora2_videofile = text_to_video_sora2(prompt, size=\"1280x720\", seconds='12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb88b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(sora2_videofile, width=1024, embed=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
