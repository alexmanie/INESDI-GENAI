{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f292f216-448c-4304-8224-0cbf9a2022c9",
   "metadata": {},
   "source": [
    "# Sora with Azure AI Foundry\n",
    "\n",
    "Sora is an AI model from OpenAI that can create realistic and imaginative video scenes from text instructions. The model is capable of generating a wide range of video content, including realistic scenes, animations, and special effects. Several video resolutions and durations are supported.\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/video-generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6091b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efafceee-6fbf-401d-bae8-824767771471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import datetime\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Video, FileLink\n",
    "from moviepy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029dd448-1591-4548-9e75-281d717a3062",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd844f89-064a-4146-97b0-8bff137f02f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Today is {datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c533a5-8e6e-426d-8010-684fc17b380b",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560fe98b-dcdc-40d7-a449-152e77ff6359",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"videos\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5143ddfb-603d-4cef-ad78-fefa7ed70c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"azure.env\")\n",
    "\n",
    "endpoint = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "api_key = os.environ['AZURE_OPENAI_API_KEY']\n",
    "\n",
    "model = \"sora\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20797e2-8ca9-4f63-954f-2bfa1723b3be",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9688580-4ed4-4e58-b162-ca62613b5e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sora(prompt, width=480, height=480, n_seconds=5):\n",
    "    \"\"\"\n",
    "    Generates a video based on the given prompt using the SORA model.\n",
    "\n",
    "    Parameters:\n",
    "    prompt (str): The text prompt to generate the video.\n",
    "    width (int): The width of the video. Supported values are 480, 854, 720, 1080, and 1920.\n",
    "    height (int): The height of the video. Supported values are 480, 854, 720, 1080, and 1920.\n",
    "    n_seconds (int): The duration of the video in seconds. Must be between 1 and 20 seconds.\n",
    "    n_variants (int): The number of video variants to generate.\n",
    "    \n",
    "    Returns:\n",
    "    str: The filename of the generated video.\n",
    "\n",
    "    Raises:\n",
    "    Exception: If the video generation job fails or no generations are found.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    api_version = 'preview'\n",
    "    headers = {\"api-key\": api_key, \"Content-Type\": \"application/json\"}\n",
    "\n",
    "    idx = datetime.datetime.today().strftime('%d%b%Y_%H%M%S')\n",
    "    suffix = prompt[:30].replace(\",\", \"_\").replace(\".\", \"_\").replace(\" \", \"_\")\n",
    "    output_filename = os.path.join(OUTPUT_DIR, f\"sora_{idx}_{suffix}.mp4\")\n",
    "\n",
    "    # 1. Create a video generation job\n",
    "    create_url = f\"{endpoint}/openai/v1/video/generations/jobs?api-version={api_version}\"\n",
    "    \n",
    "    body = {\n",
    "        \"prompt\": prompt,\n",
    "        \"width\": width,  # 480x480, 480x854, 854x480, 720x720, 720x1280, 1280x720, 1080x1080, 1080x1920, 1920x1080.\n",
    "        \"height\": height,  # 480x480, 480x854, 854x480, 720x720, 720x1280, 1280x720, 1080x1080, 1080x1920, 1920x1080.\n",
    "        \"n_seconds\": n_seconds,  # between 1 and 20 seconds\n",
    "        \"model\": model,  # SORA model\n",
    "    }\n",
    "    response = requests.post(create_url, headers=headers, json=body)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    now = datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')\n",
    "    print(f\"{now} Full response JSON:\", response.json())\n",
    "    print()\n",
    "\n",
    "    job_id = response.json()[\"id\"]\n",
    "    now = datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')\n",
    "    print(f\"{now} Job created: {job_id}\")\n",
    "\n",
    "    # 2. Poll for job status\n",
    "    status_url = f\"{endpoint}/openai/v1/video/generations/jobs/{job_id}?api-version={api_version}\"\n",
    "    status = None\n",
    "\n",
    "    while status not in (\"succeeded\", \"failed\", \"cancelled\"):\n",
    "        time.sleep(5)  # Wait before polling again\n",
    "        status_response = requests.get(status_url, headers=headers).json()\n",
    "        status = status_response.get(\"status\")\n",
    "        now = datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')\n",
    "        print(f\"{now} Job status: {status}\")\n",
    "\n",
    "    # 3. Retrieve generated video\n",
    "    if status == \"succeeded\":\n",
    "        generations = status_response.get(\"generations\", [])\n",
    "\n",
    "        if generations:\n",
    "            now = datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')\n",
    "            print(f\"\\n{now} ✅ Done. Video generation succeeded.\")\n",
    "            generation_id = generations[0].get(\"id\")\n",
    "            video_url = f\"{endpoint}/openai/v1/video/generations/{generation_id}/content/video?api-version={api_version}\"\n",
    "            video_response = requests.get(video_url, headers=headers)\n",
    "\n",
    "            if video_response.ok:\n",
    "                # Downloading the video\n",
    "                print(\"\\nDownloading the video...\")\n",
    "                with open(output_filename, \"wb\") as file:\n",
    "                    file.write(video_response.content)\n",
    "                    print(f\"SORA Generated video saved: '{output_filename}'\")\n",
    "\n",
    "                elapsed = time.time() - start\n",
    "                minutes, seconds = divmod(elapsed, 60)\n",
    "                print(f\"Done in {minutes:.0f} minutes and {seconds:.0f} seconds\")\n",
    "\n",
    "                return output_filename\n",
    "        else:\n",
    "            raise Exception(\"Error. No generations found in job result.\")\n",
    "    else:\n",
    "        raise Exception(f\"Error. Job did not succeed. Status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b865643f-526e-409c-8ba8-9d8ee7a8ea46",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950e76ca-3c62-45cb-bfbe-de46f8acf1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A young boy and his father playing together in the ocean on the beach.\"\n",
    "\n",
    "generated_video = sora(prompt, width=480, height=480, n_seconds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd7d05f-5314-4bee-aab2-209d60adab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(generated_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1df45d-e0aa-4994-a97a-0d195344618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_link = FileLink(path=generated_video)\n",
    "video_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6196535-f0f9-4bd6-a5b2-041f7a96d68b",
   "metadata": {},
   "source": [
    "## Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a869c9-2a21-4141-9167-b504e28f9c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A close up view of a glass sphere that has a zen garden within it. There is a small dwarf in the sphere who is raking the zen garden and creating patterns in the sand.\"\n",
    "\n",
    "generated_video = sora(prompt, width=480, height=480, n_seconds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8a2d32-1a32-45f4-86e4-41379c79e6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(generated_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e6ce17-0165-4f3c-837c-ee0259c4fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_link = FileLink(path=generated_video)\n",
    "video_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab9b28e-1715-4c40-8a62-da9f443b3218",
   "metadata": {},
   "source": [
    "## Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6fdc78-666a-48f1-bc34-6d205853557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Several giant wooly mammoths approach treading through a snowy meadow, their long wooly fur lightly blows in the wind as they walk, snow covered trees and dramatic snow capped mountains in the distance, mid afternoon light with wispy clouds and a sun high in the distance creates a warm glow, the low camera view is stunning capturing the large furry mammal with beautiful photography, depth of field.\"\n",
    "\n",
    "generated_video = sora(prompt,\n",
    "                       width=1280,\n",
    "                       height=720,\n",
    "                       n_seconds=5,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee2ddc6-e664-49d5-93e3-388ba3febbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(generated_video, width=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3356def-6777-4143-8ddd-9f2b18d923c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_link = FileLink(path=generated_video)\n",
    "video_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9661cd10-e188-4df2-b757-2c4b0614e3f2",
   "metadata": {},
   "source": [
    "## Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2598dd4e-db78-4ef1-9e7c-e9d6c6ad5386",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Drone view of waves crashing against the rugged cliffs along Big Sur's garay point beach. The crashing blue waters create white-tipped waves, while the golden light of the setting sun illuminates the rocky shore. A small island with a lighthouse sits in the distance, and green shrubbery covers the cliff's edge. The steep drop from the road down to the beach is a dramatic feat, with the cliff's edges jutting out over the sea. This is a view that captures the raw beauty of the coast and the rugged landscape of the Pacific Coast Highway.\"\n",
    "\n",
    "generated_video = sora(prompt,\n",
    "                       width=1280,\n",
    "                       height=720,\n",
    "                       n_seconds=15,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771bb959-f85d-4fd3-a647-83fc31e6ad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(generated_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14979f4-d297-478a-a7dd-4c790ea12db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_link = FileLink(path=generated_video)\n",
    "video_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac85e2a9-fb55-4f9e-893c-e5172a465766",
   "metadata": {},
   "source": [
    "## Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9b850e-d477-444b-96ea-fd9dbc6813ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Extreme close up of a 25 year old woman's eye blinking, cinematic film shot in 70mm, depth of field, vivid colors, cinematic\"\n",
    "\n",
    "generated_video = sora(prompt,\n",
    "                       width=1280,\n",
    "                       height=720,\n",
    "                       n_seconds=5,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e76495a-217a-486a-9877-19155e4d7e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(generated_video, width=860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f21e2c-75bb-4974-9e3c-dc96e658fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_link = FileLink(path=generated_video)\n",
    "video_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ed2ddc-8cd9-4d98-9f9b-8d10142d3bb7",
   "metadata": {},
   "source": [
    "## Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4713e1d-e219-4c06-9e3b-60b101a219a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Extreme close up of a 50 year old male's eye blinking, cinematic film shot in 70mm, depth of field, vivid colors, cinematic\"\n",
    "\n",
    "generated_video = sora(prompt,\n",
    "                       width=1280,\n",
    "                       height=720,\n",
    "                       n_seconds=5,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281c2346-7841-40e2-bffc-77616f49ab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(generated_video, width=860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6033e815-71bf-4988-8711-e1aa8f8dd28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_link = FileLink(path=generated_video)\n",
    "video_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125f4680-b315-42f7-a7d9-e4696df3d0ce",
   "metadata": {},
   "source": [
    "## Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd05049d-235b-46f4-8014-8da05daf7f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Reflections in the window of a train traveling through the Tokyo suburbs.\"\n",
    "\n",
    "generated_video = sora(prompt,\n",
    "                       width=1280,\n",
    "                       height=720,\n",
    "                       n_seconds=10,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b79463f-0ba5-48e5-85da-e01ce0575ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(generated_video, width=860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9add9e-ded0-4faf-a7e1-59db37d935b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_link = FileLink(path=generated_video)\n",
    "video_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6439e9d-5b89-4317-8108-973df8e12e83",
   "metadata": {},
   "source": [
    "## Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f28c2f-5f04-4514-ab33-77abe283bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A drone view of flock of paper airplanes multicolors flutters through a dense jungle, weaving around trees as if they were migrating birds.\"\n",
    "\n",
    "generated_video = sora(prompt,\n",
    "                       width=1280,\n",
    "                       height=720,\n",
    "                       n_seconds=7,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fb2a60-2c8b-4867-aa80-e77301856b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(generated_video, width=860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f327fb07-0788-4b76-b4b2-6ed45cff6633",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_link = FileLink(path=generated_video)\n",
    "video_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8529a33c-cdbd-49d3-a1f6-b2860d69087d",
   "metadata": {},
   "source": [
    "## Another exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55420c94-944f-491a-86b2-17bcad5a15c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Street of Tokyo, rainy day with people walking in a street, restaurants in the street.\"\n",
    "\n",
    "generated_video = sora(prompt,\n",
    "                       width=1280,\n",
    "                       height=720,\n",
    "                       n_seconds=7,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4a5811-483f-49fb-98eb-4b612258ad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(generated_video, width=860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325d9bc1-294b-4f0d-be04-9b89c1deae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_link = FileLink(path=generated_video)\n",
    "video_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21876621-5cce-49f8-9f67-5579ecf12a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $OUTPUT_DIR -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fa82c7-a118-47ff-9e0b-9b743984a0f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
